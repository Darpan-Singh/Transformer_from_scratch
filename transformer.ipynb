{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport math","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-17T09:00:54.322881Z","iopub.execute_input":"2024-03-17T09:00:54.323407Z","iopub.status.idle":"2024-03-17T09:00:54.330051Z","shell.execute_reply.started":"2024-03-17T09:00:54.323370Z","shell.execute_reply":"2024-03-17T09:00:54.328480Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"class InputEmbeddings(nn.Module):\n    def __init__(self,d_model:int,vocab_size:int):\n        super().__init__()\n        self.d_model = d_model\n        self.vocab_size = vocab_size\n        embedding = nn.Embedding(vocab_size,d_model)\n    \n    def forward(self,x):\n        return self.embedding(x)*(math.sqrt(d_model))","metadata":{"execution":{"iopub.status.busy":"2024-03-17T09:00:54.332529Z","iopub.execute_input":"2024-03-17T09:00:54.333051Z","iopub.status.idle":"2024-03-17T09:00:54.345112Z","shell.execute_reply.started":"2024-03-17T09:00:54.333015Z","shell.execute_reply":"2024-03-17T09:00:54.343683Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self,d_model:int,seq_len:int,dropout:float):\n        super().__init__()\n        self.d_model = d_model\n        self.seq_len = seq_len\n        self.dropout = nn.Dropout(dropout)\n        #PE matrix(seq_len x d_model)\n        pe = torch.zeros(seq_len,d_model)\n        #vector of shape(seq_len x 1)\n        Position = torch.arange(0,seq_len,dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0,d_model,2).float() * (-math.log(10000.0)/d_model))\n        \n        pe[:,0::2] = torch.sin(Position*div_term)\n        pe[:,1::2] = torch.cos(Position*div_term)\n        #Add a dimension 1 tensor\n        pe = pe.unsqueeze(0)\n        #to save the tensor in file along with the state of model\n        self.register_buffer('pe',pe)\n        \n    def forward(self,x):\n        x = x + (pe[:,:x.shape[1],:]).requires_grad(False)\n        return self.dropout(x)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T09:00:54.346746Z","iopub.execute_input":"2024-03-17T09:00:54.348429Z","iopub.status.idle":"2024-03-17T09:00:54.364241Z","shell.execute_reply.started":"2024-03-17T09:00:54.348382Z","shell.execute_reply":"2024-03-17T09:00:54.362926Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"class LayerNormalization(nn.Module):\n    def __init__(self,eps:int=10**-6)->None:\n        super().__init__()\n        self.eps = eps\n        #alpha are multiplied\n        self.alpha = nn.Parameter(torch.ones(1))\n        # bias added\n        self.bias = nn.Parameter(torch.zeros(1))\n        \n    def forward(self,x):\n        mean = x.mean(dim=-1,keepdim=True)\n        std = x.std(dim=-1, keepdim=True)\n        return self.alpha * (x- self.mean)/(self.std-eps) + self.bias","metadata":{"execution":{"iopub.status.busy":"2024-03-17T09:00:54.367345Z","iopub.execute_input":"2024-03-17T09:00:54.367953Z","iopub.status.idle":"2024-03-17T09:00:54.385983Z","shell.execute_reply.started":"2024-03-17T09:00:54.367916Z","shell.execute_reply":"2024-03-17T09:00:54.384522Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"class FeedForwardBlock(nn.Module):\n    def __init__(self,d_model:int,d_ff:int,dropout:float):\n        super().__init__()\n        self.linear_1 = nn.Linear(d_model,d_ff)\n        self.dropout = nn.Dropout(dropout)\n        self.linear_2 = nn.Linear(d_ff,d_model)\n        \n    def forward(self,x):\n        return self.linear_2(self.dropout(torch.relu(self.linear_1(x))))\n        ","metadata":{"execution":{"iopub.status.busy":"2024-03-17T09:00:54.387422Z","iopub.execute_input":"2024-03-17T09:00:54.387828Z","iopub.status.idle":"2024-03-17T09:00:54.400524Z","shell.execute_reply.started":"2024-03-17T09:00:54.387796Z","shell.execute_reply":"2024-03-17T09:00:54.399234Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"class MultiHeadAttentionBlock(nn.Module):\n    def __init__(self,d_model:int, h:int, dropout:float)->None:\n        super().__init__()\n        self.d_model = d_model\n        self.h = h\n        assert d_model%h == 0, \"d_model is not divisible by h\" \n        self.dropout = nn.Dropout(dropout)\n        \n        self.d_k = d_model//h\n        self.w_q = nn.Linear(d_model,d_model)\n        self.w_k = nn.Linear(d_model,d_model)\n        self.w_v = nn.Linear(d_model,d_model)\n        \n        self.w_o = nn.Linear(d_model,d_model)\n    \n    @staticmethod\n    def attention(query,key,value,mask,dropout:float):\n        d_k = query.shape[-1]\n        \n        attention_scores=(query @ key.transpose(-2,-1))/math.sqrt(d_k)\n        if mask is not none:\n            attention_scores.mask_fill_(mask == 0,-1e9)\n        # batch,h, seq_len,seq_len\n        attention_scores = attention_scores.softmax(dim = -1)\n        if dropout is not none:\n            attention_scores = dropout(attention_scores)\n            \n        return (attention_scores @ value), attention_scores\n    \n    def forward(self,q, k, v, mask):\n        query = self.w_q(q)\n        key = self.w_k(k)\n        value = self.w_v(v)\n        \n        query = query.view(query.shape[0],query.shape[1],self.h,self.d_k).transpose(1,2)\n        key = key.view(key.shape[0],key.shape[1],self.h,self.d_k).transpose(1,2)\n        value = value.view(value.shape[0],value.shape[1],self.h,self.d_k).transpose(1,2)\n        \n        x,self.attention_scores = MultiHeadAttentionBlock.attention(query,key,value,mask,self.dropout)\n        #now we concatenate the multi heads and multiply w_o\n        x = x.transpose(1,2).contiguous().view(x.shape[0],-1,self.h * self.d_k)\n        \n        return self.w_o(x)\n        ","metadata":{"execution":{"iopub.status.busy":"2024-03-17T09:00:54.402306Z","iopub.execute_input":"2024-03-17T09:00:54.403120Z","iopub.status.idle":"2024-03-17T09:00:54.419949Z","shell.execute_reply.started":"2024-03-17T09:00:54.403084Z","shell.execute_reply":"2024-03-17T09:00:54.418610Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"class ResidualConnection(nn.Module):\n    def __init__(self,dropout:float)->None:\n        super().__init__()\n        self.dropout = nn.Dropout(dropout)\n        self.norm = LayerNormalization()\n        \n    def forward(self,x,sublayer):\n        return x + self.dropout(sublayer(self.norm(x)))","metadata":{"execution":{"iopub.status.busy":"2024-03-17T09:00:54.422257Z","iopub.execute_input":"2024-03-17T09:00:54.423431Z","iopub.status.idle":"2024-03-17T09:00:54.438810Z","shell.execute_reply.started":"2024-03-17T09:00:54.423395Z","shell.execute_reply":"2024-03-17T09:00:54.437596Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"class EncoderBlock(nn.Module):\n    def __init__(self,self_attention_block:MultiHeadAttentionBlock, feed_forward_block:FeedForwardBlock, dropout:float)->None:\n        super().__init__()\n        self.self_attention_block = self_attention_block\n        self.feed_forward_block = feed_forward_block\n        self.residual_connections = nn.ModuleList([ResidualConnection(dropout) for _ in range(2)]) \n        \n    def forward(self,x,src_mask):\n        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x,x,x,src_mask))\n        x = self.residual_connections[1](x, self.feed_forward_block)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-03-17T09:00:54.441732Z","iopub.execute_input":"2024-03-17T09:00:54.442993Z","iopub.status.idle":"2024-03-17T09:00:54.458373Z","shell.execute_reply.started":"2024-03-17T09:00:54.442943Z","shell.execute_reply":"2024-03-17T09:00:54.456925Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self,layers : nn.ModuleList)->None:\n        super().__init__()\n        self.layers = layers\n        self.norm = LayerNormalization()\n        \n    def forward(self,x,mask):\n        for layer in self.layers:\n            x = layer(x,mask)\n            \n        return self.norm(x)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T09:00:54.526058Z","iopub.execute_input":"2024-03-17T09:00:54.527352Z","iopub.status.idle":"2024-03-17T09:00:54.535524Z","shell.execute_reply.started":"2024-03-17T09:00:54.527313Z","shell.execute_reply":"2024-03-17T09:00:54.534323Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"class DecoderBlock(nn.Module):\n    def __init__(self,self_attention_block:MultiHeadAttentionBlock,cross_attention_block:MultiHeadAttentionBlock,feed_forward_block:FeedForwardBlock,dropout:float):\n        super().__init__()\n        self.self_attention_block = self_attention_block\n        self.cross_attention_block = cross_attention_block\n        self.feed_forward_block = feed_forward_block\n#         self.dropout = nn.Dropout(dropout)\n        self.residual_connections = nn.ModuleList(ResidualConnection(dropout) for _ in range(3))\n        \n    def forward(self,x,encoder_output,src_mask,tgt_mask):\n        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x,x,x,tgt_mask))\n        x = self.residual_connections[1](x, lambda x: self.cross_attention_block(x,encoder_output,encoder_output,src_mask))\n        x = self.residual_connections[2](x, self.feed_forward_block)        \n        return x","metadata":{"execution":{"iopub.status.busy":"2024-03-17T09:00:54.538257Z","iopub.execute_input":"2024-03-17T09:00:54.539051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, layers:nn.ModuleList):\n        super().__init__()\n        self.layers = layers\n        self.norm = LayerNormalization()\n        \n    def forward(self,x,encoder_output,src_mask,tgt_mask):\n        for layer in self.layers:\n            x = layer(x,encoder_output,src_mask,tgt_mask)\n        return self.norm(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ProjectionLayer(nn.Module):\n    def __init__(self,d_model:int,vocab_size:int):\n        super().__init()\n#         self.d_model = d_model\n#         self.vocab_size = vocab_size\n        self.proj = nn.Linear(d_model,vocab_size)\n    def forward(self,x):\n        return torch.log_softmax(self.proj(x),dim = -1)\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(self,encoder:Encoder,decoder:Decoder,src_embed:InputEmbeddings, tgt_embed:InputEmbeddings,src_pos:PositionalEncoding,tgt_pos:PositionalEncoding,projection_layer:ProjectionLayer):\n        self.encoder = encoder\n        self.decoder = decoder\n        self.src_embed = src_embed\n        self.tgt_embed = tgt_embed\n        self.src_pos = src_pos\n        self.tgt_pos = tgt_pos\n        self.projection_layer = projection_layer\n        \n    def encode(self,src,src_mask):\n        src = self.src_embed(src_mask)\n        src = self.src_pos(src_mask)\n        return self.encoder(src,src_mask)\n    \n    def decode(self, encoder_output,src_mask, tgt , tgt_mask):\n        tgt = self.tgt_embed(tgt_mask)\n        tgt = self.tgt_pos(tgt_mask)\n        return self.decoder(encoder_output,tgt,src_mask,tgt_mask)\n    \n    def project(self,x):\n        return self.projection_layer(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_transformer(src_vocab_size:int,tgt_vocab_size:int, src_seq_len:int,tgt_seq_len:int,d_model:int = 512, N : int = 6, h:int = 8,dropout: float=0.1, d_ff:int =2048):\n    src_embed = InputEmbeddings(d_model,src_vocab_size)\n    tgt_embed = InputEmbeddings(d_model,tgt_vocab_size)\n    \n    src_pos = PositionalEncoding(d_model,src_seq_len,dropout)\n    tgt_pos = PositionalEncoding(d_model,tgt_seq_len,dropout)\n    \n    encoder_blocks = []\n    for _ in range(N):\n        encoder_self_attention_block = MultiHeadSelfAttention(d_model,h,dropout)\n        feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\n        encoder_block = EncoderBlock(encoder_self_attention_block,feed_forward_block,dropout)\n        encoder_blocks.append(encoder_block)\n        \n    decoder_blocks = []\n    for _ in range(N):\n        decoder_self_attention_block = MultiHeadSelfAttention(d_model,h,dropout)\n        decoder_cross_attention_block = MultiHeadSelfAttention(d_model,h,dropout)\n        feed_forward_block = FeedForwardBlock(d_model,d_ff,dropout)\n        decoder_block = DecoderBlock(decoder_self_attention_block,decoder_cross_attention,feed_forward_block,dropout)\n        decoder_blocks.append(decoder_block)\n        \n    encoder = Encoder(nn.ModuleList(encoder_blocks))\n    decoder = Decoder(nn.ModuleList(decoder_blocks))\n    \n    projection_layer = ProjectionLayer(d_model,tgt_vocab_size)\n    \n    transformer = Transformer(enncoder,decoder,src_embed,tgt_embed,src_pos,tgt_pos,projection_layer)\n    \n    #initialize parameters\n    for p in transformer.parameters():\n        if p.dim()>1:\n            nn.init.xavier_uniform_(p)   \n        \n    return transformer\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Training**","metadata":{}},{"cell_type":"code","source":"# !pip install tokenizers\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader,random_split\n# from dataset import BilingualDataset, causal_mask\n# from model import build_transformer\n\nfrom datasets import load_dataset\nfrom tokenizers import Tokenizer\nfrom tokenizers.models import WordLevel\nfrom tokenizers.trainers import WordLevelTrainer\nfrom tokenizers.pre_tokenizers import Whitespace\nfrom pathlib import Path\nfrom torch.utils.tensorboard import SummaryWriter\nfrom tqdm import tqdm\nimport warnings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_all_sentences(ds,lang):\n    for item in ds:\n        yield item['translation'][lang]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_or_build_tokenizer(config, ds, lang):\n    tokenizer_path = Path(config['tokenizer_file'].format(lang))\n    if not Path.exists(tokenizer_path):\n        tokenizer = Tokenizer(WordLevel(unk_token='[UNK]'))\n        pre_tokenizer = Whitespace()\n        trainer = WordLevelTrainer(special_tokens = [\"[UNK]\",\"[PAD]\",\"[SOS]\",\"[EOS]\"], min_frquency=2)\n        tokenizer.train_from_iterator(get_all_sentences(ds,lang),trainer = trainer)\n        tokenizer.save(str(tokenizer_path))\n    else:\n        tokenizer = Tokenizer.from_file(str(tokenizer_path))\n        \n    return tokenizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"90-10 for train-validation","metadata":{}},{"cell_type":"code","source":"def get_ds(config):\n    ds_raw = load_dataset('opus_books',f'{config[\"lang_src\"]}-{config[\"lang_tgt\"]}',split = 'train')\n    tokenizer_src = get_or_build_tokenizer(config,ds_raw,\"lang_src\")\n    tokenizer_tgt = get_or_build_tokenizer(config,ds_raw,\"lang_tgt\")\n    \n    train_ds_size = int(0.9 * len(ds_raw))\n    val_ds_size = len(ds_raw)-train_ds_size\n    train_ds_raw,val_ds_raw = random_split(ds_raw,[train_ds_size,val_ds_size])\n    \n    train_ds = BilingualDataset(train_ds_raw,tokenizer_src,tokenizer_tgt,config['lang_src'], config['lang_tgt'],config['seq_len'])\n    val_ds = BilingualDataset(val_ds_raw,tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'],config['seq_len'])\n    \n    max_len_src =0\n    max_len_tgt =0\n    \n    for item in ds_raw:\n        src_ids = tokenizer_src.encode(item['translation'][config['lang_src']]).ids\n        tgt_ids = tokenizer_src.encode(item['translation'][config['lang_tgt']]).ids\n        max_len_src = max(max_len_src,len(src_ids))\n        max_len_tgt = max(max_len_tgt, len(tgt_ids))\n        \n    print(f' Max length of source sentence: {max_len_src}')\n    print(f'Max length of target sentence: {max_len_tgt}')\n    \n    train_dataloader = Dataloader(train_ds, batch_size = config['batch_size'], shuffle =True)\n    val_dataloader = Dataloader(val_ds, batch_size=1, shuffle =True)\n    \n    return train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model(config, vocab_src_len, vocab_tgt_len):\n    model = build_transformer(vocab_src_len, vocab_tgt_len, config['seq_len'], config['seq_len'], config['d_model'])\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(config):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f'Using device {device}')\n    Path(config['model_folder']).mkdir(parents = True , exist_ok = True)\n    train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n    model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n    \n    writer = SummaryWriter(config['experiment_name'])\n    \n    optimizer = torch.optimizer.Adam(model.parameters(), lr=config['lr'], eps = 1e-9)\n    initial_epoch =0\n    global_step = 0\n    if config['preload']:\n        model_filename = get_weights_file_path(config,config['preload'])\n        print(f'Preloading model {model_filename}')\n        state = torch.load(model_filename)\n        initial_epoch = state['epoch']+1\n        optimizer.load_state_dict(state['optimizer_state_dict'])\n        global_step = state['global_step']\n    loss_fn = nn.CrossEntropyLoss(ignore_index = tokenizer_src.token_to_id('[PAD]'),label_smoothing = 0.1).to(device)\n    \n    for epochs in range(initial_epoch,config['num_epochs']):\n        model.train()\n        batch_iterator = tqdm(train_dataloader,desc = f'Processing epoch {epoch:02d}')\n        for batch in batch_iterato:\n            encoder_input = batch['encoder_input'].to(device)\n            decoder_input = batch['decoder_input'].to(device)\n            encoder_mask = batch['encoder_mask'].to(device)\n            decoder_mask = batch['decoder_mask'].to(device)\n            \n            encoder_output = model.encode(encoder_input,encoder_mask)\n            decoder_output = model.decode(encoder_output,encoder_mask,decoder_input,decoder_mask)\n            proj_output = model.project(decoder_output)\n            \n            label = batch['label'].to(device)\n            loss = loss_fn(proj_ouput.view(-1,tokenizer_tgt.get_vocab_size()),label.view(-1))\n            batch_iterator.set_postfix({f\"loss\":f\"{loss.item():6.3f}\"})\n            \n            writer.add_scalar('train loss', loss.item(),global_step)\n            writer.flush()\n            loss.backward()\n            \n            optimizer.step()\n            optimizer.zero_grad()\n            global_step+=1\n            model_filename = get_weights_file_path(config, f'{epoch:02d}')\n            torch.save({\n                'epoch' : epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'global_step': global_step\n            }, model_filename)\n    \n    if __name__ == '__main__':\n        warnings.filterwarnings('ignore')\n        config = get_config()\n        train_model(config)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"dataset.py","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import dataset\nfrom typing import Any\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BilingualDataset(Dataset):\n    def __init__(self,ds,tokenizer_src,tokenizer_tgt,src_lang,tgt_lang,seq_len)->None:\n        super().__init__()\n        self.ds= ds\n        self.tokenizer_src = tokenizer_src\n        self.tokenizer_tgt = tokenizer_tgt\n        self.src_lang = src_lang\n        self.tgt_lang = tgt_lang\n\n        self.sos_token = torch.Tensor([tokenizer_src.token_to_id(['SOS'])], dtype = torch.int64)\n        self.eos_token = torch.Tensor([tokenizer_src.token_to_id(['EOS'])], dtype = torch.int64)\n        self.pad_token = torch.Tensor([tokenizer_src.token_to_id(['PAD'])], dtype = torch.int64)\n        \n    def __len__(self):\n        return len(self.ds)\n    \n    def __getitem__(self,index: Any)->Any:\n        src_target_pair = self.ds[index]\n        src_text = src_target_pair['translation'][self.src_lang]\n        tgt_text = src_target_pair['translation'][self.tgt_lang]\n        \n        enc_input_tokens = self.tokenizer_src.encode(src_text).ids\n        dec_input_tokens = self.tokenizer_tgt.encode(tgt_text).ids\n        enc_num_padding_tokens = seq_len - len(self.enc_input_tokens)-2\n        dec_num_padding_tokens = seq_len - len(dec_input_tokens)-1\n        \n        if enc_num_padding_tokens<0 or dec_num_padding_tokens<0:\n            raise ValueError('Sentence is too long')\n            \n        encoder_input = torch.cat(\n            [\n                self.sos_token,\n                torch.tensor(enc_input_tokens,dtype=torch.int64),\n                self.eos_token,\n                torch.tensor([self.pad_token] * enc_num_padding_tokens, dtype=torch.int64)\n            ]\n        )\n        decoder_input = torch.cat(\n            [\n                self.sos_token,\n                torch.tensor(enc_input_tokens, dtype=int64),\n                torch.tensor([self.pad_token]*dec_num_padding_tokens, dtype=torch.int64)\n            ]\n        )\n        \n        label = torch.cat(\n            [\n                torch.tensor(dec_input_tokens, dtype=int64),\n                self.eos_token,\n                torch.tensor([self.pad_token]*dec_num_padding_tokens, dtype=torch.int64)\n            ]\n        )\n        \n        assert encoder_input.size(0)== self.seq_len\n        assert decoder_input.size(0) == self.seq_len\n        assert label.size(0) == self.seq_len\n        \n        return {\n            \"encoder_input\":encoder_input,\n            \"decoder_input\":decoder_input,\n            \"encoder_mask\": [encoder_input != pad_token].unsqueeze(0).unsqueeze(0).int(),\n            \"decoder_mask\": [decoder_input != pad_token].unsqueeze(0).unsqueeze(0).int() & causal_mask(decoder_input.size(0)),\n            \"label\": label,\n            \"src_text\":src_text,\n            \"tgt_text\":tgt_text\n        }\n    \n    def causal_mask(size):\n        mask = torch.triu(torch.ones(1,size,size),diagonal=1).type(torch.int())\n        return mask ==0\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Config.py\n","metadata":{}},{"cell_type":"code","source":"def get_config():\n    return {\n        \"batch_size\" : 8,\n        \"num_epochs\" : 2,\n        \"lr\" : 10**-4,\n        \"seq_Len\" : 350,\n        \"d_model\": 512,\n        \"lang_src\" : \"en\",\n        \"lang_tgt\" : \"it\",\n        \"model_folder\" : \"weights\",\n        \"model_filename\" : \"tmodel_\",\n        \"preload\": None,\n        \"tokenizer_file\" : \"tokenizer{0}.json\",\n        \"experiment_name\" : \"runs/tmodel\"\n    }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_weights_file_path(config, epoch : str):\n    model_folder = config['model_folder']\n    model_basename = config['model_basename']\n    model_filename = f\"{model_basename}{epoch}.pt\"\n    return str(Path('.')/model_folder/model_filename)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}